{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Statistics\n",
    "\n",
    "Inferential statistics involves drawing conclusions about a population from a sample. \n",
    "\n",
    "A sample **statistic** is a quantity calculated from the sample values. Typical notation is $\\bar{x}$ for the sample mean, $s$ for the sample standard deviation. The goal of inferential statistics is to estimate values for parameters of the population, such as its mean $\\mu$ and its standard deviation $\\sigma$. \n",
    "\n",
    "Suppose we draw a sample of size $n$. The particular set of values obtained are denoted $x_1, x_2 \\cdots x_n$. These are particular realizations of the random variables $X_1, X_2 \\cdots X_n$. We have a **random sample** if they are independent of each other and identically distributed (iid). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "A function $g(X_1, X_2 \\cdots X_n)$ designed to estimate a population parameter is called an **estimator**. For example, the function\n",
    "$$\n",
    "g(X_1, X_2 \\cdots X_n) = \\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i\n",
    "$$\n",
    "is an estimator for $\\mu$. Note that we could choose some other function as an estimator: a trimmed mean or a median are examples. The value computed from a particular sample is the **estimate**, and is denoted by a hat over the parameter. For example, an estimate of $\\mu$ is $\\hat{\\mu}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Bias and Variance of estimators\n",
    "Estimator functions are designed to estimate population parameters. Given a choice among estimators, we can develop criteria to select the best one among them. The main criteria are bias and efficiency. For an estimator function $g$ designed to estimate the population parameter $\\theta$,\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{Bias} &\\equiv E(g) - \\theta \\\\\n",
    "\\text{var}(g) &\\equiv E\\left[(g-E(g))^2\\right]\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "where the expectations are taken over all samples from the population. Clearly, we prefer estimators with low or zero bias and small variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error\n",
    "\n",
    "A metric that incorporates both estimator bias and variance is the mean squared error (MSE). For a given estimator $g(X_1,X_2,\\cdots X_n)$ and population parameter $\\theta$,\n",
    "\n",
    "$$\n",
    "MSE \\equiv E\\left[(g-\\theta)^2\\right] = E\\left[g^2 - 2 \\theta\\;g + \\theta^2\\right] = E(g^2) -2\\theta\\;E(g) + \\theta^2 \n",
    "$$\n",
    "\n",
    "Now, for any random variable $Y, E(Y^2) = \\text{var}(Y) + E(Y)^2$. So,\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "MSE &= E(g^2) -2\\theta\\;E(g) + \\theta^2\\\\ \n",
    "&= [E(g)^2 + \\text{var}(g)]-2\\theta\\;E(g) + \\theta^2\\\\\n",
    "&= [E(g) - \\theta]^2 + \\text{var}(g)\n",
    "\\end{split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator for population mean $\\mu$\n",
    "\n",
    "Consider estimators for the population mean $\\mu$. Each random variable $X_i$ has an expected value $\\mu$ and variance $\\sigma^2$. So, if we pick one of them as our estimator for the mean, say $g(X_1,X_2,\\cdots X_n) = X_1$, we will have an unbiased estimator with variance $\\sigma^2$. However, it is possible to do better than that.The sample mean $\\bar{X}$ is also unbiased but is more **efficient** because it has a lower standard deviation:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(\\bar{X}) &= E\\left[\\frac{1}{n}\\sum_{i=1}^n X_i\\right] = \\frac{1}{n}\\sum_{i=1}^n E(X_i) = \\frac{1}{n}\\; n\\mu = \\mu \\\\ \\\\\n",
    "\\text{var}(\\bar{X}) &= \\frac{1}{n^2}\\text{var}\\sum X_i = \\frac{1}{n^2} \\sum\\text{var}( X_i) +\\sum_{i<j} 2 \\text{cov}(X_i,X_j)\\\\\n",
    " &= \\frac{1}{n^2} \\sum\\text{var} (X_i) = \\frac{1}{n^2}\\; n\\sigma^2 = \\frac{\\sigma^2}{n}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Here, we have used the fact that $\\text{cov}(X_i,X_j) = 0\\; \\forall\\; i,j$ since the $\\{X_i\\}$ are all independent of each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator for population variance $\\sigma^2$\n",
    "Let $g(X_1,X_2,\\cdots X_n) = \\sum (X_i - \\bar{X})^2$. Then\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "g &= \\sum (X_i^2 -2\\bar{X}X_i + \\bar{X}^2) = \\sum X_i^2 -2n\\bar{X}^2 + n \\bar{X}^2 = \\sum X_i^2 - n \\bar{X}^2\\\\\n",
    "  \\\\\n",
    "E(g) &= \\sum E(X_i^2) - n E(\\bar{X}^2)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We now use the fact that for any random variable $Y, E(Y^2) = \\text{var}(Y) + E(Y)^2$. So,\n",
    "$$\n",
    "\\begin{split}\n",
    "E(g)&= \\sum(\\sigma^2 + \\mu^2) - n\\left(\\frac{\\sigma^2}{n}+\\mu^2\\right)\\\\\n",
    "&= n(\\sigma^2 + \\mu^2) - (\\sigma^2 + n\\mu^2)\\\\\n",
    "&= (n-1)\\sigma^2\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "This implies that the sum of squared deviations from the mean is a biased estimator of the population variance. However, this is easily fixed. The **sample variance**, $s^2$, defined as\n",
    "$$\n",
    "s^2 \\equiv \\frac{1}{n-1} \\sum_{i=1}^n (X_i-\\bar{X})^2\n",
    "$$\n",
    "gives us an unbiased estimator of the population variance $\\sigma^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample t-test\n",
    "\n",
    "With a sample of size $n$, mean $\\bar{x}$, standard deviation $s$, and population mean $\\mu$, the test statistic \n",
    "$$\n",
    "t = \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}}\n",
    "$$\n",
    "has the t distribution with $n-1$ degrees of freedom.\n",
    "\n",
    "In hypothesis testing, we normally compute the p-value, which is the probability of occurrence of values more extreme than the computed test statistic. This depends on the form of the alternative hypothesis.\n",
    "$$\n",
    "\\begin{split}\n",
    "H_0 &: \\mu = 0 \\\\\n",
    "H_a &: \\mu \\ne 0 \\\\\n",
    "p &= P[T \\le -|t|] + P[T \\ge |t|] \\hspace{1in}\\text{Two-tailed t test}\\\\\n",
    "\\\\\n",
    "H_0 &: \\mu = 0 \\\\\n",
    "H_a &: \\mu \\lt 0 \\\\\n",
    "p &= P[T \\le -|t|] \\hspace{1in}\\text{Lower-tailed t test}\\\\\n",
    "\\\\\n",
    "H_0 &: \\mu = 0 \\\\\n",
    "H_a &: \\mu \\gt 0 \\\\\n",
    "p &= P[T \\ge |t|] \\hspace{1in}\\text{Upper-tailed t test}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8498368520005377, 0.09737624227318431)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=1.8498368520005373, pvalue=0.09737624227318435)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo of scipy.stats one sample t test function\n",
    "\n",
    "np.random.seed(12345)\n",
    "n=10\n",
    "v1 = stats.norm.rvs(size=n)  # Standard normal random variates\n",
    "\n",
    "xbar = np.mean(v1)\n",
    "s = np.std(v1, ddof=1)    # ddof=1 uses (n-1) for the denominator, so gives us sample sd\n",
    "\n",
    "# Default behavior of ttest_1samp:\n",
    "# H0: mu = 0, Ha: mu not equal to zero\n",
    "\n",
    "t =  xbar/ (s/np.sqrt(n))    \n",
    "p = 2*(1-stats.t.cdf(t,n-1)) # Two-sided test, so twice the tail probability. Note that degrees of freedom = n-1\n",
    "t,p\n",
    "stats.ttest_1samp(v1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, -2.23606797749979, 0.013567791664809134)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 43\n",
    "xbar = 40\n",
    "n = 125\n",
    "s = 15\n",
    "t =  (xbar-mu)/ (s/np.sqrt(n))\n",
    "p = stats.t.cdf(t,n-1)\n",
    "n, t,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04992258704151217"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1.6572349701441826"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1.9728699462074992"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.t.cdf(-1.658,124)\n",
    "stats.t.ppf(0.05,124)    # Percent Point Function (inverse of cdf)\n",
    "\n",
    "stats.t.ppf(0.025,185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.452984716810821"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3822396/3)/(96092902/185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6534284283390934"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f.ppf(0.95,3,185)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
